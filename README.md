#nextGPU
## nextGPU 是什么？
nextGPU 是一个基于去中心化算力网络的平台，​专注于为AI工作流提供算力支持。它通过汇聚市场上的闲置GPU算力资源，对这些资源进行互联互通、性能测量等处理，构建成一个能够高效服务于AI工作流的硬件基础设施。当用户提交AI任务请求时，nextGPU 会智能调度任务至最合适的GPU算力节点上执行，并将处理结果返回给用户。

## 我是算力提供者，如何在 nextGPU 上赚钱？
nextGPU 的核心是利用去中心化的闲置算力提供服务。因此，当用户支付算力使用费后，平台仅收取15%的服务费，​剩余85%的费用将直接支付给算力提供者。作为提供者，您可以随时（定期或灵活）从平台提取您的收益。

## 使用 nextGPU 有什么优势？

nextGPU 的核心优势在于极具竞争力的价格。因为它利用的是闲置算力资源，其使用成本远低于同类竞品。
​例如：​​ 生成一张 1024x1024 分辨率、20 步的图片，在某平台上需花费 0.1 元。而使用 nextGPU，​仅需 0.0023 元，成本仅为前者的约 1/43 (或 2.3%)​。

## nextGPU 如何保障 AI 任务输出完整结果？
nextGPU 在保障任务完整性方面与其它去中心化平台不同：

​### 严格节点筛选：​​ 平台会对每个算力节点进行基于真实AI任务的测量。无法通过测量任务的节点将被标记为“未通过”​，AI任务不会调度到这类节点上。
​### 智能任务监控与重试：​​ 在执行过程中，nextGPU 会实时监控每个AI任务的运行时间。一旦发现任务未能在预期时间内完成​（通常由节点问题导致），平台会立即将该任务重新调度给其他合格节点执行，并将原节点标记为失效状态。

## nextGPU 如何保障工作流任务的高效执行？
nextGPU 的高效秘诀在于其智能的任务处理能力​：

1. 区别于仅简单分发任务的平台，nextGPU 会分析每个AI工作流任务的结构。
2. 平台能自动将可并行化的任务拆分成子任务。
3. 然后将这些子任务智能调度并分发给多个合适的闲置算力节点并行处理。
这种方式显著提升了AI任务的执行速度，同时最大化地利用了闲置的GPU算力资源。